{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step1: Create the Python Script\n",
    "\n",
    "In the cell below, you will need to complete the Python script and run the cell to generate the file using the magic `%%writefile` command. Your main task is to complete the following methods for the `PersonDetect` class:\n",
    "* `load_model`\n",
    "* `predict`\n",
    "* `draw_outputs`\n",
    "* `preprocess_outputs`\n",
    "* `preprocess_inputs`\n",
    "\n",
    "For your reference, here are all the arguments used for the argument parser in the command line:\n",
    "* `--model`:  The file path of the pre-trained IR model, which has been pre-processed using the model optimizer. There is automated support built in this argument to support both FP32 and FP16 models targeting different hardware.\n",
    "* `--device`: The type of hardware you want to load the model on (CPU, GPU, MYRIAD, HETERO:FPGA,CPU)\n",
    "* `--video`: The file path of the input video.\n",
    "* `--output_path`: The location where the output stats and video file with inference needs to be stored (results/[device]).\n",
    "* `--max_people`: The max number of people in queue before directing a person to another queue.\n",
    "* `--threshold`: The probability threshold value for the person detection. Optional arg; default value is 0.60."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting person_detect.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile person_detect.py\n",
    "\n",
    "# TODO: Make variable for number of queues and declare it along with everything else\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "from openvino.inference_engine import IENetwork, IECore\n",
    "import os\n",
    "import cv2\n",
    "import argparse\n",
    "import sys\n",
    "\n",
    "# to average inference request results\n",
    "from statistics import mean \n",
    "\n",
    "class Queue:\n",
    "    \"\"\"\n",
    "    Class for dealing with queues.\n",
    "    \n",
    "    Performs basic operations for queues like adding to a queue, getting the queues \n",
    "    and checking the coordinates for queues.\n",
    "    \n",
    "    Attributes:\n",
    "        queues: A list containing the queues data\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.queues=[]\n",
    "\n",
    "    def add_queue(self, points):\n",
    "        \"\"\"\n",
    "        Add points to the queue.\n",
    "        Args:\n",
    "            points: A list of points to be added.\n",
    "        Raises:\n",
    "            TypeError: points is None.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.queues.append(points)\n",
    "\n",
    "    def check_coords(self, coords, initial_w, initial_h):\n",
    "        \"\"\"\n",
    "        Checks queue coordinates.\n",
    "        Args:\n",
    "            coords: A list of the coordinates.\n",
    "            initial_w: initial width\n",
    "            initial_h: initial height\n",
    "        \"\"\"\n",
    "        \n",
    "        result={k+1:0 for k in range(len(self.queues))}\n",
    "        \n",
    "        # make a dummy variable to check over it\n",
    "        check_list = ['0', '1' , '2', '3']\n",
    "        \n",
    "        for coord in coords:\n",
    "            xmin = int(coord[3] * initial_w)\n",
    "            ymin = int(coord[4] * initial_h)\n",
    "            xmax = int(coord[5] * initial_w)\n",
    "            ymax = int(coord[6] * initial_h)\n",
    "            \n",
    "            check_list[0] = xmin\n",
    "            check_list[1] = ymin\n",
    "            check_list[2] = xmax\n",
    "            check_list[3] = ymax\n",
    "            \n",
    "            for i, j in enumerate(self.queues):\n",
    "                if check_list[0]>j[0] and check_list[2]<j[2]:\n",
    "                    result[i+1]+=1\n",
    "        return result\n",
    "\n",
    "\n",
    "class PersonDetect:\n",
    "    \"\"\"\n",
    "    Class for the Person Detection Model.\n",
    "    \n",
    "    Performs person detection and preprocessing.\n",
    "    \n",
    "    Attributes:\n",
    "        model_weights: A string containing model weights path.\n",
    "        model_structure: A string conatining model structure path.\n",
    "        device: A string conatining device name.\n",
    "        threshold: A floating point number containing threshold value.\n",
    "        input_name: A list of input names.\n",
    "        input_shape: A tuple of the input shape.\n",
    "        output_name: A list of output names.\n",
    "        output_shape: A tuple of the output shape.\n",
    "        core: IECore object.\n",
    "        net: Loaded net object.\n",
    "        exec_net: executable imported network\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model_name, device, threshold=0.60):\n",
    "        \"\"\"\n",
    "        Inits PersonDetect class with model_name, device, threshold.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.model_weights=model_name+'.bin'\n",
    "        self.model_structure=model_name+'.xml'\n",
    "        self.device=device\n",
    "        self.threshold=threshold\n",
    "\n",
    "        # deprecated\n",
    "        try:         \n",
    "             self.model=IENetwork(self.model_structure, self.model_weights)\n",
    "        except Exception as e:\n",
    "            raise ValueError(\"Could not Initialise the network. Have you enterred the correct model path?\")\n",
    "\n",
    "        print('Creating model...')\n",
    "        self.input_name=next(iter(self.model.inputs))\n",
    "        self.input_shape=self.model.inputs[self.input_name].shape\n",
    "        self.output_name=next(iter(self.model.outputs))\n",
    "        self.output_shape=self.model.outputs[self.output_name].shape\n",
    "\n",
    "    def load_model(self):\n",
    "        core = IECore()\n",
    "        self.net = core.read_network(model=self.model_structure, weights=self.model_weights)        \n",
    "        print(self.net,\" network read\")\n",
    "        if self.device == 'MYRIAD':\n",
    "            REQUESTS = 4\n",
    "        elif self.device == 'GPU':\n",
    "            REQUESTS = 4 # i5-6500TE integrated GPU\n",
    "        elif self.device == 'CPU':            \n",
    "            REQUESTS = 4 # i5-6500TE number of cores          \n",
    "        elif 'FPGA' in self.device:            \n",
    "            REQUESTS = 5 # recommended max. inf requests.\n",
    "        else: \n",
    "            REQUESTS = 1 # fallback if unknown case qty of inference requests is 1\n",
    "        \n",
    "        self.exec_net = core.load_network(network=self.net, device_name=self.device, num_requests=REQUESTS)\n",
    "        print(self.exec_net,\" executable network loaded on\", self.device)\n",
    "        print(REQUESTS, \"Async Inference Requests\")\n",
    "\n",
    "        \n",
    "    def predict(self, image):\n",
    "        \"\"\"\n",
    "        Make asynchronous predictions from images.\n",
    "        Args:\n",
    "            image: List of the image data.\n",
    "        Returns:\n",
    "            The outputs and the image.\n",
    "        \"\"\"\n",
    "        \n",
    "        input_name = self.input_name\n",
    "\n",
    "        input_img = self.preprocess_input(image)\n",
    "              \n",
    "        input_dict={input_name: input_img}  \n",
    "        \n",
    "        # Start asynchronous inference for specified request.\n",
    "\n",
    "        infer_request_handle = self.exec_net.start_async(request_id=0, inputs=input_dict)\n",
    "        infer_status = infer_request_handle.wait()\n",
    "        if infer_status == 0:\n",
    "            outputs = infer_request_handle.outputs[self.output_name]\n",
    "            \n",
    "        return outputs, image\n",
    "    \n",
    "    def draw_outputs(self, coords, frame, initial_w, initial_h):\n",
    "        \"\"\"\n",
    "        Draws outputs or predictions on image.\n",
    "        Args:\n",
    "            coords: The coordinates of predictions.\n",
    "            image: The image on which boxes need to be drawn.\n",
    "        Returns:\n",
    "            the frame\n",
    "            the count of people\n",
    "            bounding boxes above threshold\n",
    "        \"\"\"\n",
    "        \n",
    "        current_count = 0\n",
    "        det = []\n",
    "        \n",
    "        for obj in coords[0][0]:\n",
    "            \n",
    "            # Draw bounding box for the detected object when it's probability \n",
    "            # is more than the specified threshold\n",
    "            if obj[2] > self.threshold:\n",
    "                xmin = int(obj[3] * initial_w)\n",
    "                ymin = int(obj[4] * initial_h)\n",
    "                xmax = int(obj[5] * initial_w)\n",
    "                ymax = int(obj[6] * initial_h)\n",
    "                cv2.rectangle(frame, (xmin, ymin), (xmax, ymax), (0, 55, 255), 1)\n",
    "                current_count = current_count + 1\n",
    "                \n",
    "                det.append(obj)\n",
    "                \n",
    "        return frame, current_count, det\n",
    "\n",
    "    def preprocess_outputs(self, outputs):\n",
    "        \"\"\"\n",
    "        Preprocess the outputs.\n",
    "        Args:\n",
    "            outputs: The output from predictions.\n",
    "        Returns:\n",
    "            Preprocessed dictionary.\n",
    "        \"\"\"\n",
    "        \n",
    "        output_dict = {}\n",
    "        for output in outputs:\n",
    "            output_name = self.output_name\n",
    "            output_img = output\n",
    "            output_dict[output_name] = output_img\n",
    "        \n",
    "        return output_dict\n",
    "    \n",
    "        return output\n",
    "        \n",
    "\n",
    "    def preprocess_input(self, image):\n",
    "      \n",
    "        input_img = image\n",
    "        \n",
    "        # Preprocessing input\n",
    "        n, c, h, w = self.input_shape\n",
    "        \n",
    "        input_img=cv2.resize(input_img, (w, h), interpolation = cv2.INTER_AREA)\n",
    "        \n",
    "        # Change image from HWC to CHW\n",
    "        input_img = input_img.transpose((2, 0, 1))\n",
    "        input_img = input_img.reshape((n, c, h, w))\n",
    "\n",
    "        return input_img\n",
    "\n",
    "\n",
    "def main(args):\n",
    "    model=args.model\n",
    "    device=args.device\n",
    "    video_file=args.video\n",
    "    max_people=args.max_people\n",
    "    threshold=args.threshold\n",
    "    output_path=args.output_path    \n",
    "    start_model_load_time=time.time()\n",
    "    pd= PersonDetect(model, device, threshold)\n",
    "    pd.load_model()\n",
    "    total_model_load_time = time.time() - start_model_load_time\n",
    "    \n",
    "    # Convert string argument to boolean\n",
    "    vertical_queue=int(args.v_queue)\n",
    "    \n",
    "    # Set defaults for cv2.puttext\n",
    "    # Choose font\n",
    "    font = cv2.FONT_HERSHEY_COMPLEX\n",
    "    \n",
    "    # Choose OpenCV BGR color\n",
    "    # Bright green for debugging\n",
    "    color = (0, 225, 0) \n",
    "    # Bright red for warnings\n",
    "    warning_color = (0, 0 , 225)\n",
    "    \n",
    "    # Choose fontscale depending on the information displayed\n",
    "    debug_scale = 1\n",
    "    queue_scale = 5\n",
    "    warning_scale = 4\n",
    "    \n",
    "    # Choose font thickness\n",
    "    normal_thickness = 2\n",
    "    queue_thickness = 6\n",
    "\n",
    "    # Get queue\n",
    "    queue=Queue()\n",
    "    \n",
    "    try:\n",
    "        queue_param=np.load(args.queue_param)\n",
    "        for q in queue_param:\n",
    "            queue.add_queue(q)\n",
    "    except:\n",
    "        print(\"error loading queue param file\")\n",
    "\n",
    "    try:\n",
    "        cap=cv2.VideoCapture(video_file)\n",
    "    except FileNotFoundError:\n",
    "        print(\"Cannot locate video file: \"+ video_file)\n",
    "    except Exception as e:\n",
    "        print(\"Something else went wrong with the video file: \", e)\n",
    "    \n",
    "    initial_w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    initial_h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    video_len = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))        \n",
    "    \n",
    "    # Get frame size information\n",
    "    w_center = int(initial_w/2)-40\n",
    "    w_left = int(initial_w/4)\n",
    "    w_further_left = int(initial_w/4)\n",
    "    w_far_left = int(initial_w/10)    \n",
    "    h_center = int(initial_h/2)  \n",
    "    h_offset = int(initial_h/7)   \n",
    "\n",
    "    out_video = cv2.VideoWriter(os.path.join(output_path, 'output_video.mp4'), cv2.VideoWriter_fourcc(*'avc1'), fps, (initial_w, initial_h), True)\n",
    "    \n",
    "    counter=0\n",
    "    start_inference_time=time.time()      \n",
    "    \n",
    "    # Create people count array in order to average results\n",
    "    people_arr=[]\n",
    "    \n",
    "    # Debug to see if vertical queue is on\n",
    "    print(\"vertical queue is\",vertical_queue, \"type\",type(vertical_queue))\n",
    "    \n",
    "    try:\n",
    "        while cap.isOpened():\n",
    "            ret, frame=cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            counter+=1\n",
    "            coords, image= pd.predict(frame)\n",
    "            frame, current_count, coords = pd.draw_outputs(coords, image, initial_w, initial_h)\n",
    "            print(coords)\n",
    "            \n",
    "            num_people = queue.check_coords(coords, initial_w, initial_h)\n",
    "            \n",
    "            total_count = len(coords)\n",
    "            \n",
    "            people_arr.append(total_count)\n",
    "            \n",
    "            # must average between the last 5 inferences \n",
    "            if len(people_arr)>5:\n",
    "                \n",
    "                # Averaged\n",
    "                avg_inf_result = int(round(mean(people_arr[len(people_arr)-5:len(people_arr)]),0))\n",
    "                total_msg = str(avg_inf_result) + \" Total People\"\n",
    "\n",
    "                print(total_msg)                \n",
    "                print(num_people,\"people in queue\")               \n",
    "\n",
    "                # Printing device\n",
    "                device_text = \"Running Inference on: \" + str(device)\n",
    "                cv2.putText(image, device_text, (15, 40), font, debug_scale, color, normal_thickness)\n",
    "\n",
    "                # Printing frame counter\n",
    "                framecount_text = \"Frame: \" + str(counter) +\"/\"+ str(video_len)\n",
    "                cv2.putText(image, framecount_text, (15, 80), font, debug_scale, color, normal_thickness)            \n",
    "\n",
    "                # Printing fps\n",
    "                fps_text = \"Video FPS: \" + str(fps)\n",
    "                cv2.putText(image, fps_text, (15, 120), font, debug_scale, color, normal_thickness)\n",
    "                \n",
    "                # Printing people_arr\n",
    "                people_arr_txt1 = \"Last 5 inference results:\"          \n",
    "                cv2.putText(image, people_arr_txt1, (15, 160), font, debug_scale, color, normal_thickness)\n",
    "                people_arr_txt2 = \"people count array: \" + str(people_arr[len(people_arr)-5:len(people_arr)])\n",
    "                cv2.putText(image, people_arr_txt2, (15, 200), font, debug_scale, color, normal_thickness)\n",
    "                                \n",
    "                out_text=\"\"\n",
    "                y_pixel=50\n",
    "                \n",
    "                # If queue is vertical check coordinates\n",
    "                if vertical_queue == 1:\n",
    "                    print(\"vertical queue:\")\n",
    "                    \n",
    "                    for j, k in num_people.items():\n",
    "                        print(\"Entered v_queue for loop\")\n",
    "                        print(j, k)                \n",
    "                        \n",
    "                        out_text += f\"{k} People in Queue {j}\"\n",
    "                        print(\"Queue results:\",out_text)\n",
    "                        \n",
    "                        if j >= int(max_people):\n",
    "                            out_text += f\" Queue full; Please move to next Queue \"\n",
    "                        cv2.putText(image, out_text, (15, y_pixel), font, debug_scale, color, normal_thickness)\n",
    "                        out_text=\"\"\n",
    "                        y_pixel+=40                       \n",
    "                        \n",
    "                else:\n",
    "                    # Writing total people detected on frame                    \n",
    "                    cv2.putText(image, str(avg_inf_result), (w_center,h_center), font, queue_scale, color, queue_thickness, cv2.LINE_AA) \n",
    "                    cv2.putText(image, \"Total People\", (w_left,h_center+h_offset), font, queue_scale, color, queue_thickness, cv2.LINE_AA)\n",
    "                    if avg_inf_result > int(max_people):\n",
    "                        cv2.putText(image, \"CAPACITY FULL\", (w_further_left,h_center+(2*h_offset)), font, warning_scale, warning_color, 2*queue_thickness, cv2.LINE_AA)\n",
    "                        cv2.putText(image, \"MOVE TO NEXT QUEUE\", (w_far_left,h_center+(3*h_offset)), font, warning_scale, warning_color, 2*queue_thickness, cv2.LINE_AA)\n",
    "\n",
    "            out_video.write(image)\n",
    "            \n",
    "        total_time=time.time()-start_inference_time    \n",
    "        total_inference_time=round(total_time, 1)\n",
    "        fps=counter/total_inference_time\n",
    "\n",
    "        with open(os.path.join(output_path, 'stats.txt'), 'w') as f:\n",
    "            f.write(str(total_inference_time)+'\\n')\n",
    "            f.write(str(fps)+'\\n')\n",
    "            f.write(str(total_model_load_time)+'\\n')\n",
    "\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"Could not run Inference: \", e)\n",
    "\n",
    "if __name__=='__main__':\n",
    "    parser=argparse.ArgumentParser()\n",
    "    parser.add_argument('--model', required=True)\n",
    "    parser.add_argument('--device', default='CPU')\n",
    "    parser.add_argument('--video', default=None)\n",
    "    parser.add_argument('--queue_param', default=None)\n",
    "    parser.add_argument('--output_path', default='/results')\n",
    "    parser.add_argument('--max_people', default=2)\n",
    "    parser.add_argument('--threshold', default=0.60)\n",
    "    parser.add_argument('--v_queue', default=0)\n",
    "    \n",
    "    args=parser.parse_args()\n",
    "\n",
    "    main(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Step\n",
    "\n",
    "Now that you've run the above cell and created your Python script, you will create your job submission shell script in the next workspace.\n",
    "\n",
    "**Note**: As a reminder, if you need to make any changes to the Python script, you can come back to this workspace to edit and run the above cell to overwrite the file with your changes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
